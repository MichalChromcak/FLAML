{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2020-2021. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License.\n",
    "\n",
    "# HPO for Fine-Tuning Pre-trained Language Models\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "\n",
    "In this notebook, we demonstrate a procedure for troubleshooting HPO failure in fine-tuning pre-trained language models (introduced in the following paper):\n",
    "\n",
    "*An Empirical Study on Hyperparameter Optimization for Fine-Tuning Pre-trained Language Models. Xueqing Liu, Chi Wang. To appear in ACL-IJCNLP 2021*\n",
    "\n",
    "FLAML requires `Python>=3.6`. To run this notebook example, please install flaml with the `notebook` and `nlp` options:\n",
    "```bash\n",
    "pip install flaml[notebook,nlp]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/xliu/Documents/xqq/Documents/work/projects/automl/FLAML/notebook\r\n"
     ]
    }
   ],
   "source": [
    "!pip install flaml[notebook,nlp]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Experimental Study (Section 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset \n",
    "\n",
    "Load the dataset using AutoTransformer.prepare_data. In this notebook, we use the Recognizing Textual Entailment (RTE) dataset and the Electra model as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/home/xliu127/.cache/huggingface/datasets/glue/rte/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n",
      "Loading cached processed dataset at /home/xliu127/.cache/huggingface/datasets/glue/rte/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4/cache-404440ecda81d9a6.arrow\n",
      "Loading cached processed dataset at /home/xliu127/.cache/huggingface/datasets/glue/rte/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4/cache-778149280c71c970.arrow\n",
      "Loading cached processed dataset at /home/xliu127/.cache/huggingface/datasets/glue/rte/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4/cache-4b5989072a90417b.arrow\n",
      "Loading cached processed dataset at /home/xliu127/.cache/huggingface/datasets/glue/rte/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4/cache-404440ecda81d9a6.arrow\n",
      "Loading cached processed dataset at /home/xliu127/.cache/huggingface/datasets/glue/rte/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4/cache-778149280c71c970.arrow\n",
      "Loading cached processed dataset at /home/xliu127/.cache/huggingface/datasets/glue/rte/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4/cache-4b5989072a90417b.arrow\n"
     ]
    }
   ],
   "source": [
    "from flaml.nlp.autotransformers import AutoTransformers\n",
    "autohf = AutoTransformers()\n",
    "preparedata_setting = {\n",
    "        \"dataset_subdataset_name\": \"glue:rte\",\n",
    "        \"pretrained_model_size\": \"google/electra-base-discriminator:base\",\n",
    "        \"data_root_path\": \"data/\",\n",
    "        \"max_seq_length\": 128,\n",
    "        }\n",
    "autohf.prepare_data(**preparedata_setting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we run grid search using Electra. By specifying `algo_mode=\"grid\"`, AutoTransformers will by default use the grid configuration recommended for the Electra model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The value for metric_name is not specified, setting it to the default value accuracy. Alternatively, you can set it to accuracy,loss\n",
      "The value for metric_mode_name is not specified, setting it to the default value max. Alternatively, you can set it to max,min\n",
      "2021-06-13 11:43:59,466\tINFO services.py:1174 -- View the Ray dashboard at \u001B[1m\u001B[32mhttp://127.0.0.1:8265\u001B[39m\u001B[22m\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (pyarrow 3.0.0 (/data/installation/anaconda3/envs/test/lib/python3.7/site-packages), Requirement.parse('pyarrow<2.0.0,>=0.17.0'), {'azureml-dataset-runtime'}).\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-4e2ec13c242f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m                     \u001B[0;34m\"algo_mode\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m\"grid\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m                    }\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0mvalidation_metric\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0manalysis\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mautohf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mautohf_settings\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/data/installation/anaconda3/envs/test/lib/python3.7/site-packages/FLAML-0.5.2-py3.7.egg/flaml/nlp/autotransformers.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, num_samples, time_budget, custom_metric_name, custom_metric_mode_name, ckpt_per_epoch, fp16, verbose, resources_per_trial, **custom_hpo_args)\u001B[0m\n\u001B[1;32m    717\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_set_search_space\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mcustom_hpo_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    718\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 719\u001B[0;31m             \u001B[0msearch_algo\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_search_algo\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjobid_config\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0malg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjobid_config\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcustom_hpo_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    720\u001B[0m             \u001B[0mscheduler\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mAutoScheduler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_scheduler_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjobid_config\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpru\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    721\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mckpt_per_epoch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mckpt_per_epoch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/test/lib/python3.7/site-packages/FLAML-0.5.2-py3.7.egg/flaml/nlp/autotransformers.py\u001B[0m in \u001B[0;36m_get_search_algo\u001B[0;34m(self, search_algo_name, search_algo_args_mode, **custom_hpo_args)\u001B[0m\n\u001B[1;32m    454\u001B[0m             \u001B[0msearch_algo_args_mode\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    455\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_search_space_hpo\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 456\u001B[0;31m             **custom_hpo_args)\n\u001B[0m\u001B[1;32m    457\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0msearch_algo\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    458\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/test/lib/python3.7/site-packages/FLAML-0.5.2-py3.7.egg/flaml/nlp/hpo/searchalgo_auto.py\u001B[0m in \u001B[0;36mfrom_method_name\u001B[0;34m(cls, search_algo_name, search_algo_args_mode, hpo_search_space, **custom_hpo_args)\u001B[0m\n\u001B[1;32m     86\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0msearch_algo_args_mode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"dft\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     87\u001B[0m                     this_search_algo_kwargs = DEFAULT_SEARCH_ALGO_ARGS_MAPPING[search_algo_name](\n\u001B[0;32m---> 88\u001B[0;31m                         \"dft\", hpo_search_space=hpo_search_space, **allowed_custom_args)\n\u001B[0m\u001B[1;32m     89\u001B[0m                 \u001B[0;32melif\u001B[0m \u001B[0msearch_algo_args_mode\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"cus\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     90\u001B[0m                     this_search_algo_kwargs = DEFAULT_SEARCH_ALGO_ARGS_MAPPING[search_algo_name](\n",
      "\u001B[0;32m/data/installation/anaconda3/envs/test/lib/python3.7/site-packages/FLAML-0.5.2-py3.7.egg/flaml/nlp/hpo/searchalgo_auto.py\u001B[0m in \u001B[0;36mdefault_search_algo_args_bs\u001B[0;34m(search_args_mode, hpo_search_space, **custom_hpo_args)\u001B[0m\n\u001B[1;32m    122\u001B[0m         \u001B[0mmin_epoch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhpo_search_space\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"num_train_epochs\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcategories\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    123\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 124\u001B[0;31m         \u001B[0;32massert\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mhpo_search_space\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"num_train_epochs\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mray\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtune\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mFloat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    125\u001B[0m         \u001B[0mmin_epoch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhpo_search_space\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"num_train_epochs\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlower\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    126\u001B[0m     default_search_algo_args = {\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "autohf_settings = {\"resources_per_trial\": {\"gpu\": 1, \"cpu\": 1},\n",
    "                    \"num_samples\": -1, # unlimited sample size\n",
    "                    \"time_budget\": 3600,\n",
    "                    \"ckpt_per_epoch\": 1,\n",
    "                    \"fp16\": True,\n",
    "                    \"algo_mode\": \"grid\"\n",
    "                   }\n",
    "validation_metric, analysis = autohf.fit(**autohf_settings,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run HPO for 1GST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "autohf_settings = {\"resources_per_trial\": {\"gpu\": 1, \"cpu\": 1},\n",
    "                    \"num_samples\": -1, # unlimited sample size\n",
    "                    \"time_budget\": time_budget,\n",
    "                    \"ckpt_per_epoch\": 5,\n",
    "                    \"fp16\": True,\n",
    "                   }\n",
    "validation_metric, analysis = autohf.fit(**autohf_settings,)\n",
    "print(validation_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}