description: finetuning test on AMLK8s

target:
  service: amlk8s
  name: ms-shared-v100

environment:
  image: pytorch/pytorch:1.4-cuda10.1-cudnn7-devel
  setup:
    - pip install transformers datasets wandb prompt_toolkit==1.0.14 --user
    - git clone https://github.com/liususan091219/FLAML.git
    - cd FLAML
    - git checkout v0.2.7
    - pip install -e.[blendsearch,ray] --user
    - cd ..
    - git clone https://github.com/NVIDIA/apex
    - cd apex
    - pip install --user -v --no-cache-dir --global-option="--cpp_ext" --global-option="--cuda_ext" ./
    - cd ..
    - rm -rf apex/.git

code:
  # local directory of the code. this will be uploaded to the server.
  # $CONFIG_DIR is expanded to the directory of this config file
  local_dir: $CONFIG_DIR/hf/

# data:
#   data upload is not required for this example

jobs:
- name: rte_grid_bert
  sku: G8
  command:
  - python run_autohf.py --server_name azureml --algo grid_search_bert --dataset_idx 0
  submit_args: &retry_args
    # Max numbers of attempts to retry job. Default: 3.
    max_attempts: 1
- name: rte_hpo
  sku: G8
  command:
  - python run_autohf.py --server_name azureml --algo hpo --dataset_idx 0
  submit_args:
    <<: *retry_args
- name: cola_grid_bert
  sku: G8
  command:
  - python run_autohf.py --server_name azureml --algo grid_search_bert --dataset_idx 2
  submit_args:
    <<: *retry_args
- name: cola_hpo
  sku: G8
  command:
  - python run_autohf.py --server_name azureml --algo hpo --dataset_idx 2
  submit_args:
    <<: *retry_args